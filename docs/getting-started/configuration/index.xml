<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>OpenELB â€“ Configuration</title><link>/docs/getting-started/configuration/</link><description>Recent content in Configuration on OpenELB</description><generator>Hugo -- gohugo.io</generator><atom:link href="/docs/getting-started/configuration/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: Configure IP Address Pools Using Eip</title><link>/docs/getting-started/configuration/configure-ip-address-pools-using-eip/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/getting-started/configuration/configure-ip-address-pools-using-eip/</guid><description>
&lt;p>This document describes how to configure an Eip object, which functions as an IP address pool for PorterLB both in BGP mode and in Layer 2 mode.&lt;/p>
&lt;p>PorterLB assigns IP addresses in Eip objects to LoadBalancer Services in the Kubernetes cluster. After that, PorterLB publishes routes destined for the Service IP addresses over BGP (in BGP mode), ARP (in Layer 2 mode for IPv4), or NDP (in Layer 2 mode for IPv6).&lt;/p>
&lt;div class="notices note">
&lt;p>NOTE&lt;/p>
&lt;div>Currently, PorterLB supports only IPv4 and will soon support IPv6.&lt;/div>
&lt;/div>
&lt;h2 id="configure-an-eip-object-for-porterlb">Configure an Eip Object for PorterLB&lt;/h2>
&lt;p>You can create an Eip object to provide an IP address pool for PorterLB. The following is an example of the Eip YAML configuration:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#204a87;font-weight:bold">apiVersion&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">network.kubesphere.io/v1alpha2&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">kind&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">Eip&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">metadata&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">name&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">eip-sample-pool&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">spec&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">address&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#0000cf;font-weight:bold">192.168.0.91-192.168.0.100&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">protocol&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">layer2&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">interface&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">eth0&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">disable&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">false&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">status&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">occupied&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">false&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">usage&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#0000cf;font-weight:bold">1&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">poolSize&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#0000cf;font-weight:bold">10&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">used&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">&amp;#34;192.168.0.91&amp;#34;: &lt;/span>&lt;span style="color:#4e9a06">&amp;#34;default/test-svc&amp;#34;&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">firstIP&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#0000cf;font-weight:bold">192.168.0.91&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">lastIP&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#0000cf;font-weight:bold">192.168.0.100&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">ready&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">true&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">v4&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">true&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The fields are described as follows:&lt;/p>
&lt;p>&lt;code>metadata&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>&lt;code>name&lt;/code>: Name of the Eip object.&lt;/li>
&lt;/ul>
&lt;p>&lt;code>spec&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>address&lt;/code>: One or more IP addresses, which will be used by PorterLB. The value format can be:&lt;/p>
&lt;ul>
&lt;li>&lt;code>IP address&lt;/code>, for example, &lt;code>192.168.0.100&lt;/code>.&lt;/li>
&lt;li>&lt;code>IP address/Subnet mask&lt;/code>, for example, &lt;code>192.168.0.0/24&lt;/code>.&lt;/li>
&lt;li>&lt;code>IP address 1-IP address 2&lt;/code>, for example, &lt;code>192.168.0.91-192.168.0.100&lt;/code>.&lt;/li>
&lt;/ul>
&lt;div class="notices note">
&lt;p>NOTE&lt;/p>
&lt;div>IP segments in different Eip objects cannot overlap. Otherwise, a resource creation error will occur.&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>&lt;code>protocol&lt;/code>: Specifies which mode of PorterLB the Eip object is used for. The value can be either &lt;code>layer2&lt;/code> or &lt;code>bgp&lt;/code>. If this field is not specified, the default value &lt;code>bgp&lt;/code> is used.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>interface&lt;/code>: NIC on which PorterLB listens for ARP or NDP requests. This field is valid only when &lt;code>protocol&lt;/code> is set to &lt;code>layer2&lt;/code>.&lt;/p>
&lt;div class="notices tip">
&lt;p>TIP&lt;/p>
&lt;div>If the NIC names of the Kubernetes cluster nodes are different, you can set the value to &lt;code>can_reach:IP address&lt;/code> (for example, &lt;code>can_reach:192.168.0.5&lt;/code>) so that PorterLB automatically obtains the name of the NIC that can reach the IP address. In this case, you must ensure that the IP address is not used by Kubernetes cluster nodes but can be reached by the cluster nodes.&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>&lt;code>disable&lt;/code>: Specifies whether the Eip object is disabled. The value can be:&lt;/p>
&lt;ul>
&lt;li>&lt;code>false&lt;/code>: PorterLB can assign IP addresses in the Eip object to new LoadBalancer Services.&lt;/li>
&lt;li>&lt;code>true&lt;/code>: PorterLB stops assigning IP addresses in the Eip object to new LoadBalancer Services. Existing Services are not affected.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;code>status&lt;/code>: Fields under &lt;code>status&lt;/code> specify the status of the Eip object and are automatically configured. When creating an Eip object, you do not need to configure these fields.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>occupied&lt;/code>: Specifies whether IP addresses in the Eip object have been used up.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>usage&lt;/code>: Specifies how many IP addresses in the Eip object have been assigned to Services.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>used&lt;/code>: Specifies the used IP addresses and the Services that use the IP addresses. The Services are displayed in the &lt;code>Namespace/Service name&lt;/code> format (for example, &lt;code>default/test-svc&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>poolSize&lt;/code>: Total number of IP addresses in the Eip object.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>firstIP&lt;/code>: First IP address in the Eip object.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>lastIP&lt;/code>: Last IP address in the Eip object.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>v4&lt;/code>: Specifies whether the address family is IPv4. Currently, PorterLB supports only IPv4 and the value can only be &lt;code>true&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>ready&lt;/code>: Specifies whether the Eip-associated program used for BGP/ARP/NDP routes publishing has been initialized. The program is integrated in PorterLB.&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Docs: Configure PorterLB in BGP Mode</title><link>/docs/getting-started/configuration/configure-porter-in-bgp-mode/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/getting-started/configuration/configure-porter-in-bgp-mode/</guid><description>
&lt;p>This document describes how to configure PorterLB in BGP mode. If PorterLB is used in Layer 2 mode, you do not need to configure PorterLB.&lt;/p>
&lt;h2 id="configure-local-bgp-properties-using-bgpconf">Configure Local BGP Properties Using BgpConf&lt;/h2>
&lt;p>You can create a BgpConf object in the Kubernetes cluster to configure the local BGP properties on PorterLB. The following is an example of the BgpConf YAML configuration:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#204a87;font-weight:bold">apiVersion&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">network.kubesphere.io/v1alpha2&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">kind&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">BgpConf&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">metadata&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">name&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">default&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">spec&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">as&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#0000cf;font-weight:bold">50000&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">listenPort&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#0000cf;font-weight:bold">17900&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">routerId&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#0000cf;font-weight:bold">192.168.0.2&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The fields are described as follows:&lt;/p>
&lt;p>&lt;code>metadata&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>&lt;code>name&lt;/code>: BgpConf object name. PorterLB recognizes only the name &lt;code>default&lt;/code>. BgpConf objects with other names will be ignored.&lt;/li>
&lt;/ul>
&lt;p>&lt;code>spec&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>&lt;code>as&lt;/code>: Local ASN, which must be different from the value of &lt;code>spec:conf:peerAS&lt;/code> in the BgpPeer configuration.&lt;/li>
&lt;li>&lt;code>listenPort&lt;/code>: Port on which PorterLB listens. The default value is &lt;code>179&lt;/code> (default BGP port number). If other components (such as Calico) in the Kubernetes cluster also use BGP and port 179, you must set a different value to avoid the conflict.&lt;/li>
&lt;li>&lt;code>routerID&lt;/code>: Local router ID, which is usually set to the IP address of the master NIC of the Kubernetes master node. If this field is not specified, the first IP address of the node where porter-manager is located will be used.&lt;/li>
&lt;/ul>
&lt;h2 id="configure-peer-bgp-properties-using-bgppeer">Configure Peer BGP Properties Using BgpPeer&lt;/h2>
&lt;p>You can create a BgpPeer object in the Kubernetes cluster to configure the peer BGP properties on PorterLB. The following is an example of the BgpPeer YAML configuration:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#204a87;font-weight:bold">apiVersion&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">network.kubesphere.io/v1alpha2&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">kind&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">BgpPeer&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">metadata&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">name&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">bgppeer-sample&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">spec&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">conf&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">peerAs&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#0000cf;font-weight:bold">50001&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">neighborAddress&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#0000cf;font-weight:bold">192.168.0.5&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">afiSafis&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#204a87;font-weight:bold">config&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">family&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">afi&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">AFI_IP&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">safi&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">SAFI_UNICAST&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">enabled&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">true&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">addPaths&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">config&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">sendMax&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#0000cf;font-weight:bold">10&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">nodeSelector&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">matchLabels&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">porter.kubesphere.io/rack&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">leaf1&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The fields are described as follows:&lt;/p>
&lt;p>&lt;code>metadata&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>&lt;code>name&lt;/code>: Name of the BgpPeer object. If there are multiple peer BGP routers, you can create multiple BgpPeer objects with different names.&lt;/li>
&lt;/ul>
&lt;p>&lt;code>spec:conf&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>&lt;code>peerAS&lt;/code>: ASN of the peer BGP router, which must be different from the value of &lt;code>spec:as&lt;/code> in the BgpConf configuration.&lt;/li>
&lt;li>&lt;code>neighborAddress&lt;/code>: IP address of the peer BGP router.&lt;/li>
&lt;/ul>
&lt;p>&lt;code>spec:afiSafis:addPaths:config&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>&lt;code>sendMax&lt;/code>: Maximum number of equivalent routes that PorterLB can send to the peer BGP router for Equal-Cost Multi-Path (ECMP) routing. The default value is &lt;code>10&lt;/code>.&lt;/li>
&lt;/ul>
&lt;p>&lt;code>spec:nodeSelector:matchLabels&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>&lt;code>porter.kubesphere.io/rack&lt;/code>: If the Kubernetes cluster nodes are deployed under different routers and each node has one PorterLB replica, you need to configure this field so that the PorterLB replica on the correct node establishes a BGP connection with the peer BGP router. By default, all porter-manager replicas will respond to the BgpPeer configuration and attempt to establish a BGP connection with the peer BGP router.&lt;/li>
&lt;/ul>
&lt;p>Other fields under &lt;code>spec:afiSafis&lt;/code> specify the address family. Currently, PorterLB supports only IPv4 and you can directly use the values in the example configuration.&lt;/p></description></item><item><title>Docs: Configure PorterLB for Multi-router Clusters (BGP Mode)</title><link>/docs/getting-started/configuration/configure-porter-for-multi-router-clusters/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/getting-started/configuration/configure-porter-for-multi-router-clusters/</guid><description>
&lt;p>This document describes how to configure PorterLB in BGP mode for Kubernetes cluster nodes deployed under multiple routers. You can skip this document if all Kubernetes cluster nodes are deployed under the same router.&lt;/p>
&lt;div class="notices note">
&lt;p>NOTE&lt;/p>
&lt;div>This document applies only to the BGP mode. The Layer 2 mode requires that all Kubernetes cluster nodes be on the same Layer 2 network (under the same router).&lt;/div>
&lt;/div>
&lt;h2 id="network-topology-before-configuration">Network Topology Before Configuration&lt;/h2>
&lt;p>This section explains why you need to perform the configuration. The following figure shows the network topology of a Kubernetes cluster before the configuration.&lt;/p>
&lt;p>&lt;img src="/images/en/docs/getting-started/configuration/configure-porter-for-multi-router-clusters/multi-router-topology-1.jpg" alt="multi-router-topology-1">&lt;/p>
&lt;p>IP addresses in the preceding figure are examples only. The topology is described as follows:&lt;/p>
&lt;ul>
&lt;li>In the Kubernetes cluster, the master and worker 1 nodes are deployed under the leaf 1 BGP router, and the worker 2 node is deployed under the leaf 2 BGP router. PorterLB is only installed under leaf 1 (by default, only one PorterLB replica is installed).&lt;/li>
&lt;li>A Service backed by two Pods is deployed in the Kubernetes cluster, and is assigned an IP address 172.22.0.2 for external access. Pod 1 and Pod 2 are deployed on worker 1 and worker 2 respectively.&lt;/li>
&lt;li>PorterLB establishes a BGP connection with leaf 1 and publishes the IP addresses of the master node and worker 1 (192.168.0.3 and 192.168.0.4) to leaf 1 as the next hop destined for the Service IP address 172.22.0.2.&lt;/li>
&lt;li>Leaf 1 establishes a BGP connection with the spine BGP router and publishes its own IP address 192.168.0.2 to the spine router as the next hop destined for the Service IP address 172.22.0.2.&lt;/li>
&lt;li>When an external client machine attempts to access the Service, the spine router forwards the Service traffic to leaf 1, and leaf 1 load balances the traffic among the master node and worker 1.&lt;/li>
&lt;li>Although Pod 2 on worker 2 can also be reached over kube-proxy, router-level load balancing is implemented only among the master node and worker 1 and the Service bandwidth is limited to the bandwidth of the master node and worker 1.&lt;/li>
&lt;/ul>
&lt;p>To resolve the problem, you need to label the Kubernetes cluster nodes and change the PorterLB Deployment configuration so that PorterLB is installed on nodes under all leaf routers. In addition, you need to specify the &lt;a href="/docs/getting-started/configuration/configure-porter-in-bgp-mode/#configure-peer-bgp-properties-using-bgppeer">spec:nodeSelector:matchLabels&lt;/a> field in the BgpPeer configuration so that the PorterLB replicas establish BGP connections with the correct BGP routers.&lt;/p>
&lt;h2 id="network-topology-after-configuration">Network Topology After Configuration&lt;/h2>
&lt;p>This section describes the configuration result you need to achieve. The following figure shows the network topology of a Kubernetes cluster after the configuration.&lt;/p>
&lt;p>&lt;img src="/images/en/docs/getting-started/configuration/configure-porter-for-multi-router-clusters/multi-router-topology-2.jpg" alt="multi-router-topology-2">&lt;/p>
&lt;p>IP addresses in the preceding figure are examples only. The topology is described as follows:&lt;/p>
&lt;ul>
&lt;li>After the configuration, PorterLB is installed on nodes under all leaf routers.&lt;/li>
&lt;li>In addition to &lt;a href="#network-topology-before-configuration">what happens before the configuration&lt;/a>, the PorterLB replica installed under leaf 2 also establishes a BGP connection with leaf 2 and publishes the worker 2 IP address 192.168.1.2 to leaf 2 as the next hop destined for the Service IP address 172.22.0.2.&lt;/li>
&lt;li>Leaf 2 establishes a BGP connection with the spine router and publishes its own IP address 192.168.1.1 to the spine router as the next hop destined for the Service IP address 172.22.0.2.&lt;/li>
&lt;li>When an external client machine attempts to access the Service, the spine router load balances the Service traffic among leaf 1 and leaf 2. Leaf 1 load balances the traffic among the master node and worker 1. Leaf 2 forwards the traffic to worker 2. Therefore, the Service traffic is load balanced among all three Kubernetes cluster nodes, and the Service bandwidth of all three nodes can be utilized.&lt;/li>
&lt;/ul>
&lt;h2 id="configuration-procedure">Configuration Procedure&lt;/h2>
&lt;h3 id="prerequisites">Prerequisites&lt;/h3>
&lt;p>You need to &lt;a href="/docs/getting-started/installation/">prepare a Kubernetes cluster where PorterLB has been installed&lt;/a>.&lt;/p>
&lt;h3 id="procedure">Procedure&lt;/h3>
&lt;div class="notices note">
&lt;p>NOTE&lt;/p>
&lt;div>The node names, leaf router names, and namespace in the following steps are examples only. You need to use the actual values in your environment.&lt;/div>
&lt;/div>
&lt;ol>
&lt;li>
&lt;p>Log in to the Kubernetes cluster and run the following commands to label the Kubernetes cluster nodes where PorterLB is to be installed:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl label --overwrite nodes master1 worker-p002 lb.kubesphere.io/v1alpha1&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>porter
&lt;/code>&lt;/pre>&lt;/div>&lt;div class="notices note">
&lt;p>NOTE&lt;/p>
&lt;div>PorterLB works properly if it is installed on only one node under each leaf router. In this example, PorterLB will be installed on master1 under leaf1 and worker-p002 under leaf2. However, to ensure high availability in a production environment, you are advised to installed PorterLB on at least two nodes under each leaf router.&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Run the following command to scale the number of porter-manager Pods to 0:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl scale deployment porter-manager --replicas&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> -n porter-system
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Run the following command to edit the porter-manager Deployment:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl edit deployment porter-manager -n porter-system
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>In the porter-manager Deployment YAML configuration, add the following fields under &lt;code>spec:template:spec&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#204a87;font-weight:bold">nodeSelector&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">kubernetes.io/os&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">linux&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">lb.kubesphere.io/v1alpha1&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">porter&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Run the following command to scale the number of porter-manager Pods to the required number (change the number &lt;code>2&lt;/code> to the actual value):&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl scale deployment porter-manager --replicas&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">2&lt;/span> -n porter-system
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Run the following command to check whether PorterLB has been installed on the required nodes.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl get po -n porter-system -o wide
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="/images/en/docs/getting-started/configuration/configure-porter-for-multi-router-clusters/verify-configuration-result.jpg" alt="verify-configuration-result">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Run the following commands to label the Kubernetes cluster nodes so that the PorterLB replicas establish BGP connections with the correct BGP routers.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl label --overwrite nodes master1 porter.kubesphere.io/rack&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>leaf1
&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl label --overwrite nodes worker-p002 porter.kubesphere.io/rack&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>leaf2
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>When creating BgpPeer objects, configure the &lt;a href="/docs/getting-started/configuration/configure-porter-in-bgp-mode/#configure-peer-bgp-properties-using-bgppeer">spec:nodeSelector:matchLabels&lt;/a> field in the BgpPeer YAML configuration for each leaf router. The following YAML configurations specify that the PorterLB replica on master1 communicates with leaf1, and the PorterLB replica on worker-p002 communicates with leaf2.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#8f5902;font-style:italic"># BgpPeer YAML for master1 and leaf1&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">nodeSelector&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">matchLabels&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">porter.kubesphere.io/rack&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">leaf1&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#8f5902;font-style:italic"># BgpPeer YAML for worker-p002 and leaf2&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">nodeSelector&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">matchLabels&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">porter.kubesphere.io/rack&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">leaf2&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ol></description></item><item><title>Docs: Configure Multiple PorterLB Replicas</title><link>/docs/getting-started/configuration/configure-multiple-porter-replicas/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/getting-started/configuration/configure-multiple-porter-replicas/</guid><description>
&lt;p>This document describes how to configure multiple PorterLB replicas to ensure high availability in a production environment. You can skip this document if PorterLB is used in a test environment. By default, only one PorterLB replica is installed in a Kubernetes cluster.&lt;/p>
&lt;ul>
&lt;li>If all Kubernetes cluster nodes are deployed under the same router (BGP mode or Layer 2 mode), you are advised to configure at least two PorterLB replicas, which are installed on two Kubernetes cluster nodes respectively.&lt;/li>
&lt;li>If the Kubernetes cluster nodes are deployed under different leaf routers (BGP mode only), you are advised to configure at least two PorterLB replicas (one replica for one node) under each leaf router. For details, see &lt;a href="/docs/getting-started/configuration/configure-porter-for-multi-router-clusters/">Configure PorterLB for Multi-router Clusters&lt;/a>.&lt;/li>
&lt;/ul>
&lt;h2 id="prerequisites">Prerequisites&lt;/h2>
&lt;p>You need to &lt;a href="/docs/getting-started/installation/">prepare a Kubernetes cluster where PorterLB has been installed&lt;/a>.&lt;/p>
&lt;h2 id="procedure">Procedure&lt;/h2>
&lt;div class="notices note">
&lt;p>NOTE&lt;/p>
&lt;div>The node names and namespace in the following steps are examples only. You need to use the actual values in your environment.&lt;/div>
&lt;/div>
&lt;ol>
&lt;li>
&lt;p>Log in to the Kubernetes cluster and run the following command to label the Kubernetes cluster nodes where PorterLB is to be installed:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl label --overwrite nodes master1 worker-p002 lb.kubesphere.io/v1alpha1&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>porter
&lt;/code>&lt;/pre>&lt;/div>&lt;div class="notices note">
&lt;p>NOTE&lt;/p>
&lt;div>In this example, PorterLB will be installed on master1 and worker-p002.&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Run the following command to scale the number of porter-manager Pods to 0:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl scale deployment porter-manager --replicas&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> -n porter-system
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Run the following command to edit the porter-manager Deployment:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl edit deployment porter-manager -n porter-system
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>In the porter-manager Deployment YAML configuration, add the following fields under &lt;code>spec:template:spec&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#204a87;font-weight:bold">nodeSelector&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">kubernetes.io/os&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">linux&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">lb.kubesphere.io/v1alpha1&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">porter&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Run the following command to scale the number of porter-manager Pods to the required number (change the number &lt;code>2&lt;/code> to the actual value):&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl scale deployment porter-manager --replicas&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">2&lt;/span> -n porter-system
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Run the following command to check whether PorterLB has been installed on the required nodes.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl get po -n porter-system -o wide
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="/images/en/docs/getting-started/configuration/configure-multiple-porter-replicas/verify-configuration-result.jpg" alt="verify-configuration-result">&lt;/p>
&lt;/li>
&lt;/ol>
&lt;div class="notices note">
&lt;p>NOTE&lt;/p>
&lt;div>&lt;ul>
&lt;li>In Layer 2 mode, PorterLB uses the leader election feature of Kubernetes to ensure that only one replica responds to ARP/NDP requests.&lt;/li>
&lt;li>In BGP mode, all PorterLB replicas will respond to the BgpPeer configuration and attempt to establish a BGP connection with the peer BGP router by default. If the Kubernetes cluster nodes are deployed under different routers, you need to perform further configuration so that the PorterLB replicas establish BGP connections with the correct BGP routers. For details, see &lt;a href="/docs/getting-started/configuration/configure-porter-for-multi-router-clusters/">Configure PorterLB for Multi-router Clusters&lt;/a>.&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div></description></item></channel></rss>